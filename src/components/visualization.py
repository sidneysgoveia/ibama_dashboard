import streamlit as st
import pandas as pd
import plotly.express as px
import numpy as np

# Importa as fun√ß√µes de formata√ß√£o
from src.utils.formatters import format_currency_brazilian, format_number_brazilian

# Importa o paginador
try:
    from src.utils.supabase_utils import SupabasePaginator
except ImportError:
    # Fallback se o arquivo n√£o existir
    class SupabasePaginator:
        def __init__(self, supabase_client):
            self.supabase = supabase_client
        
        def get_filtered_data(self, selected_ufs=None, year_range=None):
            # M√©todo simples sem pagina√ß√£o como fallback
            result = self.supabase.table('ibama_infracao').select('*').limit(50000).execute()
            df = pd.DataFrame(result.data)
            
            if selected_ufs and not df.empty:
                df = df[df['UF'].isin(selected_ufs)]
            
            if year_range and 'DAT_HORA_AUTO_INFRACAO' in df.columns:
                try:
                    df['DAT_HORA_AUTO_INFRACAO'] = pd.to_datetime(df['DAT_HORA_AUTO_INFRACAO'], errors='coerce')
                    df = df[
                        (df['DAT_HORA_AUTO_INFRACAO'].dt.year >= year_range[0]) &
                        (df['DAT_HORA_AUTO_INFRACAO'].dt.year <= year_range[1])
                    ]
                except:
                    pass
            
            return df

class DataVisualization:
    def __init__(self, database=None):
        """Inicializa o componente de visualiza√ß√£o com a conex√£o do banco de dados."""
        self.database = database
        
        # Inicializa o paginador se estiver usando Supabase
        if database and database.is_cloud and database.supabase:
            self.paginator = SupabasePaginator(database.supabase)
        else:
            self.paginator = None

    def _ensure_unique_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Garante que os dados sejam √∫nicos por NUM_AUTO_INFRACAO.
        FUN√á√ÉO CR√çTICA para evitar contagem duplicada.
        """
        if df.empty:
            return df
        
        if 'NUM_AUTO_INFRACAO' in df.columns:
            # Remove valores nulos primeiro
            df_valid = df[df['NUM_AUTO_INFRACAO'].notna() & (df['NUM_AUTO_INFRACAO'] != '')]
            
            if not df_valid.empty:
                # Remove duplicatas baseado em NUM_AUTO_INFRACAO
                original_count = len(df_valid)
                df_unique = df_valid.drop_duplicates(subset=['NUM_AUTO_INFRACAO'], keep='first')
                unique_count = len(df_unique)
                
                if original_count != unique_count:
                    print(f"‚ö†Ô∏è DUPLICATAS REMOVIDAS: {original_count} registros ‚Üí {unique_count} √∫nicos")
                
                return df_unique
            else:
                print("‚ö†Ô∏è Nenhum NUM_AUTO_INFRACAO v√°lido encontrado")
                return df
        else:
            print("‚ö†Ô∏è Coluna NUM_AUTO_INFRACAO n√£o encontrada - contagem pode estar incorreta")
            return df

    def _get_filtered_data(self, selected_ufs: list, year_range: tuple) -> pd.DataFrame:
        """Obt√©m dados filtrados usando pagina√ß√£o quando necess√°rio (m√©todo legacy)."""
        
        if self.paginator:
            # Usa pagina√ß√£o para buscar todos os dados
            print("üîÑ Usando pagina√ß√£o para buscar todos os dados...")
            df = self.paginator.get_filtered_data(selected_ufs, year_range)
        else:
            # Fallback para m√©todo tradicional (DuckDB ou erro no Supabase)
            print("‚ö†Ô∏è Usando m√©todo tradicional (sem pagina√ß√£o)")
            try:
                if self.database.is_cloud:
                    # Tenta com limite alto
                    result = self.database.supabase.table('ibama_infracao').select('*').limit(50000).execute()
                    df = pd.DataFrame(result.data)
                else:
                    # DuckDB - usa query direta
                    df = self.database.execute_query("SELECT * FROM ibama_infracao")
                
                # Aplica filtros localmente
                if selected_ufs and not df.empty:
                    df = df[df['UF'].isin(selected_ufs)]
                
                if year_range and 'DAT_HORA_AUTO_INFRACAO' in df.columns:
                    try:
                        df['DAT_HORA_AUTO_INFRACAO'] = pd.to_datetime(df['DAT_HORA_AUTO_INFRACAO'], errors='coerce')
                        df = df[
                            (df['DAT_HORA_AUTO_INFRACAO'].dt.year >= year_range[0]) &
                            (df['DAT_HORA_AUTO_INFRACAO'].dt.year <= year_range[1])
                        ]
                    except:
                        pass
                
            except Exception as e:
                st.error(f"Erro ao obter dados: {e}")
                df = pd.DataFrame()
        
        # GARANTIA DE UNICIDADE - SEMPRE aplica
        return self._ensure_unique_data(df)

    def _get_filtered_data_advanced(self, selected_ufs: list, date_filters: dict) -> pd.DataFrame:
        """Obt√©m dados filtrados usando os novos filtros avan√ßados de data."""
        
        if self.paginator:
            # Usa pagina√ß√£o para buscar todos os dados
            print("üîÑ Usando pagina√ß√£o para buscar todos os dados...")
            df = self.paginator.get_all_records()
        else:
            # Fallback para m√©todo tradicional (DuckDB ou erro no Supabase)
            print("‚ö†Ô∏è Usando m√©todo tradicional (sem pagina√ß√£o)")
            try:
                if self.database.is_cloud:
                    # Tenta com limite alto
                    result = self.database.supabase.table('ibama_infracao').select('*').limit(50000).execute()
                    df = pd.DataFrame(result.data)
                else:
                    # DuckDB - usa query direta
                    df = self.database.execute_query("SELECT * FROM ibama_infracao")
                
            except Exception as e:
                st.error(f"Erro ao obter dados: {e}")
                return pd.DataFrame()
        
        # GARANTIA DE UNICIDADE - SEMPRE aplica primeiro
        df = self._ensure_unique_data(df)
        
        if df.empty:
            return df
        
        # Aplica filtro de UF
        if selected_ufs and 'UF' in df.columns:
            df = df[df['UF'].isin(selected_ufs)]
        
        # Aplica filtros de data avan√ßados
        df = self._apply_date_filter_to_dataframe(df, date_filters)
        
        return df

    def _apply_date_filter_to_dataframe(self, df: pd.DataFrame, date_filters: dict) -> pd.DataFrame:
        """Aplica filtros de data ao DataFrame."""
        if df.empty or 'DAT_HORA_AUTO_INFRACAO' not in df.columns:
            return df
        
        try:
            # Converte coluna de data
            df['DATE_PARSED'] = pd.to_datetime(df['DAT_HORA_AUTO_INFRACAO'], errors='coerce')
            df_with_date = df[df['DATE_PARSED'].notna()].copy()
            
            if df_with_date.empty:
                return df_with_date
            
            if date_filters["mode"] == "simple":
                # Filtro simples por anos
                mask = df_with_date['DATE_PARSED'].dt.year.isin(date_filters["years"])
                return df_with_date[mask]
            
            else:
                # Filtro avan√ßado por per√≠odos
                masks = []
                for year, months in date_filters["periods"].items():
                    year_mask = df_with_date['DATE_PARSED'].dt.year == year
                    month_mask = df_with_date['DATE_PARSED'].dt.month.isin(months)
                    masks.append(year_mask & month_mask)
                
                if masks:
                    final_mask = masks[0]
                    for mask in masks[1:]:
                        final_mask = final_mask | mask
                    return df_with_date[final_mask]
                else:
                    return pd.DataFrame()
        
        except Exception as e:
            st.error(f"Erro ao aplicar filtro de data: {e}")
            return df

    # ======================== M√âTODOS AVAN√áADOS ========================

    def create_overview_metrics_advanced(self, selected_ufs: list, date_filters: dict):
        """Cria as m√©tricas de vis√£o geral usando dados √∫nicos garantidos."""
        if not self.database:
            st.warning("Banco de dados n√£o dispon√≠vel.")
            return

        try:
            with st.spinner("Carregando dados √∫nicos..."):
                df = self._get_filtered_data_advanced(selected_ufs, date_filters)
            
            if df.empty:
                st.warning("Nenhum dado encontrado para os filtros selecionados.")
                return

            # Dados j√° s√£o √∫nicos (garantido pelo _ensure_unique_data)
            total_infracoes = len(df)
            metric_note = "infra√ß√µes √∫nicas (garantido)"
            
            # Debug: Verifica se realmente n√£o h√° duplicatas
            if 'NUM_AUTO_INFRACAO' in df.columns:
                unique_count = df['NUM_AUTO_INFRACAO'].nunique()
                if unique_count != total_infracoes:
                    print(f"üö® ERRO: Ainda h√° duplicatas! {total_infracoes} registros vs {unique_count} √∫nicos")
                    # For√ßa corre√ß√£o
                    df = df.drop_duplicates(subset=['NUM_AUTO_INFRACAO'], keep='first')
                    total_infracoes = len(df)
            
            # Valor total das multas
            try:
                df['VAL_AUTO_INFRACAO_NUMERIC'] = pd.to_numeric(
                    df['VAL_AUTO_INFRACAO'].astype(str).str.replace(',', '.'), 
                    errors='coerce'
                )
                valor_total_multas = df['VAL_AUTO_INFRACAO_NUMERIC'].sum()
                if np.isnan(valor_total_multas):
                    valor_total_multas = 0
            except:
                valor_total_multas = 0
            
            # Total de munic√≠pios - USA COD_MUNICIPIO para maior precis√£o
            if 'COD_MUNICIPIO' in df.columns:
                total_municipios = df['COD_MUNICIPIO'].nunique()
            elif 'MUNICIPIO' in df.columns:
                # Fallback para nome se c√≥digo n√£o estiver dispon√≠vel
                total_municipios = df['MUNICIPIO'].nunique()
            else:
                total_municipios = 0

            # Exibe m√©tricas
            col1, col2, col3 = st.columns(3)
            col1.metric("Total de Infra√ß√µes", format_number_brazilian(total_infracoes))
            col2.metric("Valor Total das Multas", format_currency_brazilian(valor_total_multas))
            col3.metric("Munic√≠pios Afetados", format_number_brazilian(total_municipios))
            
            # Info com garantia de unicidade
            st.caption(f"üìä Dados √∫nicos: {total_infracoes:,} {metric_note} | {date_filters['description']}")

        except Exception as e:
            st.error(f"Erro ao calcular m√©tricas: {e}")

    def create_state_distribution_chart_advanced(self, selected_ufs: list, date_filters: dict):
        """Cria gr√°fico de distribui√ß√£o por estado com dados √∫nicos garantidos."""
        try:
            df = self._get_filtered_data_advanced(selected_ufs, date_filters)
            
            if df.empty or 'UF' not in df.columns:
                st.warning("Dados de UF n√£o dispon√≠veis.")
                return
            
            # Dados j√° s√£o √∫nicos, apenas conta por UF
            uf_counts = df['UF'].value_counts().head(15)
            method_note = "infra√ß√µes √∫nicas (garantido)"
            
            if not uf_counts.empty:
                chart_df = pd.DataFrame({
                    'UF': uf_counts.index,
                    'total': uf_counts.values
                })
                
                fig = px.bar(
                    chart_df, 
                    x='UF', 
                    y='total', 
                    title="<b>Distribui√ß√£o de Infra√ß√µes por Estado</b>", 
                    color='total',
                    labels={'UF': 'Estado', 'total': f'N¬∫ de Infra√ß√µes ({method_note})'}
                )
                
                # Adiciona nota sobre m√©todo
                fig.add_annotation(
                    text=f"* Contagem: {method_note}",
                    xref="paper", yref="paper",
                    x=1, y=1.02, xanchor='right', yanchor='bottom',
                    showarrow=False,
                    font=dict(size=10, color="gray")
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
        except Exception as e:
            st.error(f"Erro no gr√°fico de estados: {e}")

    def create_municipality_hotspots_chart_advanced(self, selected_ufs: list, date_filters: dict):
        """Cria gr√°fico dos munic√≠pios com mais infra√ß√µes usando dados √∫nicos garantidos."""
        try:
            df = self._get_filtered_data_advanced(selected_ufs, date_filters)
            
            if df.empty:
                st.warning("Dados n√£o dispon√≠veis.")
                return
            
            # Verifica se temos os campos necess√°rios
            required_fields = ['MUNICIPIO', 'UF']
            if not all(field in df.columns for field in required_fields):
                st.warning("Campos necess√°rios para an√°lise de munic√≠pios n√£o encontrados.")
                return
            
            # Remove valores vazios nos campos necess√°rios
            df_clean = df[
                df['MUNICIPIO'].notna() & 
                df['UF'].notna() &
                (df['MUNICIPIO'] != '') & 
                (df['UF'] != '')
            ].copy()
            
            if df_clean.empty:
                st.warning("Dados v√°lidos n√£o dispon√≠veis ap√≥s limpeza.")
                return
            
            # M√©todo preferido: usar c√≥digo do munic√≠pio se dispon√≠vel
            if 'COD_MUNICIPIO' in df.columns:
                # Remove c√≥digos vazios
                df_clean = df_clean[
                    df_clean['COD_MUNICIPIO'].notna() & 
                    (df_clean['COD_MUNICIPIO'] != '')
                ]
                
                if df_clean.empty:
                    st.warning("C√≥digos de munic√≠pio n√£o dispon√≠veis.")
                    return
                
                # Conta infra√ß√µes por c√≥digo do munic√≠pio (dados j√° s√£o √∫nicos)
                muni_counts = df_clean.groupby(['COD_MUNICIPIO', 'MUNICIPIO', 'UF']).size().reset_index(name='total_infracoes')
                muni_counts = muni_counts.nlargest(10, 'total_infracoes')
                
                method_note = "* Contagem por c√≥digo IBGE (infra√ß√µes √∫nicas garantidas)"
                
            else:
                # Fallback: usar nome do munic√≠pio
                st.caption("‚ö†Ô∏è Usando nomes de munic√≠pios (podem haver inconsist√™ncias)")
                
                # Conta infra√ß√µes por nome do munic√≠pio (dados j√° s√£o √∫nicos)
                muni_counts = df_clean.groupby(['MUNICIPIO', 'UF']).size().reset_index(name='total_infracoes')
                muni_counts = muni_counts.nlargest(10, 'total_infracoes')
                
                method_note = "* Contagem por nome (infra√ß√µes √∫nicas garantidas)"
            
            if not muni_counts.empty:
                # Cria label combinado para exibi√ß√£o
                muni_counts['local'] = muni_counts['MUNICIPIO'].str.title() + ' (' + muni_counts['UF'] + ')'
                
                fig = px.bar(
                    muni_counts.sort_values('total_infracoes'), 
                    y='local', 
                    x='total_infracoes', 
                    orientation='h',
                    title="<b>Top 10 Munic√≠pios com Mais Infra√ß√µes</b>",
                    labels={'local': 'Munic√≠pio', 'total_infracoes': 'N¬∫ de Infra√ß√µes √önicas'},
                    text='total_infracoes'
                )
                
                # Adiciona informa√ß√£o sobre o m√©todo usado
                fig.add_annotation(
                    text=method_note,
                    xref="paper", yref="paper",
                    x=1, y=-0.1, xanchor='right', yanchor='top',
                    showarrow=False,
                    font=dict(size=10, color="gray")
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
        except Exception as e:
            st.error(f"Erro no gr√°fico de munic√≠pios: {e}")

    def create_fine_value_by_type_chart_advanced(self, selected_ufs: list, date_filters: dict):
        """Cria gr√°fico de valores de multa por tipo com dados √∫nicos garantidos."""
        try:
            df = self._get_filtered_data_advanced(selected_ufs, date_filters)
            
            if df.empty or 'TIPO_INFRACAO' not in df.columns:
                return
            
            # Converte valores
            df['VAL_AUTO_INFRACAO_NUMERIC'] = pd.to_numeric(
                df['VAL_AUTO_INFRACAO'].astype(str).str.replace(',', '.'), 
                errors='coerce'
            )
            
            # Remove valores inv√°lidos
            df_clean = df[
                df['VAL_AUTO_INFRACAO_NUMERIC'].notna() & 
                df['TIPO_INFRACAO'].notna() & 
                (df['TIPO_INFRACAO'] != '')
            ]
            
            if df_clean.empty:
                return
            
            # Agrupa por tipo (dados j√° s√£o √∫nicos)
            type_values = df_clean.groupby('TIPO_INFRACAO')['VAL_AUTO_INFRACAO_NUMERIC'].sum().nlargest(10)
            
            if not type_values.empty:
                chart_df = pd.DataFrame({
                    'TIPO_INFRACAO': type_values.index,
                    'valor_total': type_values.values
                })
                
                chart_df['TIPO_INFRACAO'] = chart_df['TIPO_INFRACAO'].str.title()
                
                fig = px.bar(
                    chart_df.sort_values('valor_total'), 
                    y='TIPO_INFRACAO', 
                    x='valor_total', 
                    orientation='h',
                    title="<b>Tipos de Infra√ß√£o por Valor de Multa (Top 10)</b>"
                )
                st.plotly_chart(fig, use_container_width=True)
                
        except Exception as e:
            st.error(f"Erro no gr√°fico de tipos: {e}")

    def create_gravity_distribution_chart_advanced(self, selected_ufs: list, date_filters: dict):
        """Cria gr√°fico de distribui√ß√£o por gravidade incluindo infra√ß√µes sem avalia√ß√£o (Baixa, M√©dia, Sem avalia√ß√£o feita)."""
        try:
            df = self._get_filtered_data_advanced(selected_ufs, date_filters)
            
            if df.empty or 'GRAVIDADE_INFRACAO' not in df.columns:
                return
            
            # Prepara DataFrame tratando valores vazios/nulos como "Sem avalia√ß√£o feita"
            df_processed = df.copy()
            df_processed['GRAVIDADE_INFRACAO'] = df_processed['GRAVIDADE_INFRACAO'].fillna('Sem avalia√ß√£o feita')
            df_processed['GRAVIDADE_INFRACAO'] = df_processed['GRAVIDADE_INFRACAO'].replace('', 'Sem avalia√ß√£o feita')
            
            # Conta infra√ß√µes por gravidade (dados j√° s√£o √∫nicos)
            gravity_counts = df_processed['GRAVIDADE_INFRACAO'].value_counts()
            method_note = "infra√ß√µes √∫nicas (garantido)"
            
            if not gravity_counts.empty:
                # Define cores espec√≠ficas para as categorias
                color_map = {
                    'Baixa': '#28a745',          # Verde
                    'M√©dia': '#ffc107',          # Amarelo  
                    'Sem avalia√ß√£o feita': '#6c757d'  # Cinza
                }
                
                # Cria lista de cores baseada nos dados (ordem: Baixa, M√©dia, Sem avalia√ß√£o feita)
                gravity_order = ['Baixa', 'M√©dia', 'Sem avalia√ß√£o feita']
                ordered_counts = []
                ordered_names = []
                ordered_colors = []
                
                for gravity in gravity_order:
                    if gravity in gravity_counts.index:
                        ordered_counts.append(gravity_counts[gravity])
                        ordered_names.append(gravity)
                        ordered_colors.append(color_map.get(gravity, '#17a2b8'))
                
                # Adiciona outras categorias que n√£o est√£o na ordem padr√£o
                for gravity, count in gravity_counts.items():
                    if gravity not in gravity_order:
                        ordered_counts.append(count)
                        ordered_names.append(gravity)
                        ordered_colors.append('#17a2b8')  # Cor padr√£o
                
                fig = px.pie(
                    values=ordered_counts,
                    names=ordered_names,
                    title=f"<b>Distribui√ß√£o por Gravidade da Infra√ß√£o ({method_note})</b>", 
                    hole=0.4,
                    color_discrete_sequence=ordered_colors
                )
                
                # Adiciona informa√ß√£o sobre dados sem avalia√ß√£o se existirem
                sem_avaliacao = gravity_counts.get('Sem avalia√ß√£o feita', 0)
                if sem_avaliacao > 0:
                    total_infracoes = gravity_counts.sum()
                    percentual_sem_avaliacao = (sem_avaliacao / total_infracoes) * 100
                    
                    fig.add_annotation(
                        text=f"* {sem_avaliacao:,} infra√ß√µes ({percentual_sem_avaliacao:.1f}%) sem avalia√ß√£o de gravidade",
                        xref="paper", yref="paper",
                        x=0.5, y=-0.1, xanchor='center', yanchor='top',
                        showarrow=False,
                        font=dict(size=10, color="gray")
                    )
                
                st.plotly_chart(fig, use_container_width=True)
                
        except Exception as e:
            st.error(f"Erro no gr√°fico de gravidade: {e}")

    def create_main_offenders_chart_advanced(self, selected_ufs: list, date_filters: dict):
        """Cria gr√°ficos dos principais infratores separados por pessoas f√≠sicas (CPF) e empresas (CNPJ) com dados √∫nicos garantidos."""
        try:
            df = self._get_filtered_data_advanced(selected_ufs, date_filters)
            
            if df.empty:
                return
            
            # Verifica se temos as colunas necess√°rias
            required_cols = ['NOME_INFRATOR', 'CPF_CNPJ_INFRATOR', 'VAL_AUTO_INFRACAO']
            if not all(col in df.columns for col in required_cols):
                st.warning("Colunas necess√°rias para an√°lise de infratores n√£o encontradas.")
                return
            
            # Remove valores inv√°lidos
            df_clean = df[
                df['NOME_INFRATOR'].notna() & 
                df['CPF_CNPJ_INFRATOR'].notna() &
                df['VAL_AUTO_INFRACAO'].notna() &
                (df['NOME_INFRATOR'] != '') & 
                (df['CPF_CNPJ_INFRATOR'] != '') &
                (df['VAL_AUTO_INFRACAO'] != '')
            ].copy()
            
            if df_clean.empty:
                st.warning("Dados v√°lidos n√£o dispon√≠veis para an√°lise de infratores.")
                return
            
            # Converte valores para num√©rico
            df_clean['VAL_AUTO_INFRACAO_NUMERIC'] = pd.to_numeric(
                df_clean['VAL_AUTO_INFRACAO'].astype(str).str.replace(',', '.'), 
                errors='coerce'
            )
            
            # Remove valores que n√£o conseguiram ser convertidos
            df_clean = df_clean[df_clean['VAL_AUTO_INFRACAO_NUMERIC'].notna()]
            
            if df_clean.empty:
                st.warning("Nenhum valor de multa v√°lido encontrado.")
                return
            
            # Fun√ß√£o para identificar CPF (formato: XXX.XXX.XXX-XX)
            def is_cpf(cpf_cnpj):
                if pd.isna(cpf_cnpj):
                    return False
                cpf_cnpj_str = str(cpf_cnpj).strip()
                # CPF tem 14 caracteres com pontos e h√≠fen: XXX.XXX.XXX-XX
                if len(cpf_cnpj_str) == 14 and cpf_cnpj_str.count('.') == 2 and cpf_cnpj_str.count('-') == 1:
                    return True
                return False
            
            # Fun√ß√£o para identificar CNPJ (formato: XX.XXX.XXX/XXXX-XX)
            def is_cnpj(cpf_cnpj):
                if pd.isna(cpf_cnpj):
                    return False
                cpf_cnpj_str = str(cpf_cnpj).strip()
                # CNPJ tem 18 caracteres com pontos, barra e h√≠fen: XX.XXX.XXX/XXXX-XX
                if len(cpf_cnpj_str) == 18 and cpf_cnpj_str.count('.') == 2 and cpf_cnpj_str.count('/') == 1 and cpf_cnpj_str.count('-') == 1:
                    return True
                return False
            
            # Separa pessoas f√≠sicas (CPF) e empresas (CNPJ)
            df_clean['is_cpf'] = df_clean['CPF_CNPJ_INFRATOR'].apply(is_cpf)
            df_clean['is_cnpj'] = df_clean['CPF_CNPJ_INFRATOR'].apply(is_cnpj)
            
            df_pessoas_fisicas = df_clean[df_clean['is_cpf']]
            df_empresas = df_clean[df_clean['is_cnpj']]
            
            # Gr√°fico 1: Top 10 Pessoas F√≠sicas (CPF) - PRIMEIRO
            if not df_pessoas_fisicas.empty:
                # Agrupa por NOME_INFRATOR e CPF_CNPJ_INFRATOR, soma os valores (dados j√° √∫nicos)
                pf_grouped = df_pessoas_fisicas.groupby(['NOME_INFRATOR', 'CPF_CNPJ_INFRATOR'])['VAL_AUTO_INFRACAO_NUMERIC'].sum().reset_index()
                pf_grouped = pf_grouped.nlargest(10, 'VAL_AUTO_INFRACAO_NUMERIC')
                
                if not pf_grouped.empty:
                    # Cria r√≥tulo combinado (nome + CPF mascarado)
                    pf_grouped['label'] = pf_grouped.apply(
                        lambda x: f"{x['NOME_INFRATOR'][:40]}{'...' if len(x['NOME_INFRATOR']) > 40 else ''}\n(CPF: {x['CPF_CNPJ_INFRATOR'][:3]}.***.***-{x['CPF_CNPJ_INFRATOR'][-2:]})", 
                        axis=1
                    )
                    
                    fig_pf = px.bar(
                        pf_grouped.sort_values('VAL_AUTO_INFRACAO_NUMERIC'), 
                        y='label', 
                        x='VAL_AUTO_INFRACAO_NUMERIC', 
                        orientation='h',
                        title="<b>Top 10 Pessoas F√≠sicas por Valor de Multa</b>",
                        labels={'label': 'Pessoa F√≠sica', 'VAL_AUTO_INFRACAO_NUMERIC': 'Valor Total (R$)'},
                        text='VAL_AUTO_INFRACAO_NUMERIC'
                    )
                    
                    # Formata os valores no eixo X como moeda
                    fig_pf.update_layout(
                        xaxis_tickformat=',.0f',
                        height=600,
                        margin=dict(l=250)  # Mais espa√ßo √† esquerda para os nomes
                    )
                    
                    # Formata os textos dos valores
                    fig_pf.update_traces(
                        texttemplate='R$ %{x:,.0f}',
                        textposition='outside'
                    )
                    
                    st.plotly_chart(fig_pf, use_container_width=True)
                    
                    # Mostra estat√≠sticas
                    total_pf = pf_grouped['VAL_AUTO_INFRACAO_NUMERIC'].sum()
                    st.caption(f"üí∞ Total: R$ {total_pf:,.2f} | üë• {len(pf_grouped)} pessoas f√≠sicas (dados √∫nicos)")
                else:
                    st.info("Nenhuma pessoa f√≠sica encontrada nos dados filtrados.")
            else:
                st.info("Nenhuma pessoa f√≠sica encontrada nos dados filtrados.")
            
            # Separador visual
            st.divider()
            
            # Gr√°fico 2: Top 10 Empresas (CNPJ) - SEGUNDO (abaixo)
            if not df_empresas.empty:
                # Agrupa por NOME_INFRATOR e CPF_CNPJ_INFRATOR, soma os valores (dados j√° √∫nicos)
                empresa_grouped = df_empresas.groupby(['NOME_INFRATOR', 'CPF_CNPJ_INFRATOR'])['VAL_AUTO_INFRACAO_NUMERIC'].sum().reset_index()
                empresa_grouped = empresa_grouped.nlargest(10, 'VAL_AUTO_INFRACAO_NUMERIC')
                
                if not empresa_grouped.empty:
                    # Cria r√≥tulo combinado (nome + CNPJ COMPLETO)
                    empresa_grouped['label'] = empresa_grouped.apply(
                        lambda x: f"{x['NOME_INFRATOR'][:40]}{'...' if len(x['NOME_INFRATOR']) > 40 else ''}\n(CNPJ: {x['CPF_CNPJ_INFRATOR']})", 
                        axis=1
                    )
                    
                    fig_empresa = px.bar(
                        empresa_grouped.sort_values('VAL_AUTO_INFRACAO_NUMERIC'), 
                        y='label', 
                        x='VAL_AUTO_INFRACAO_NUMERIC', 
                        orientation='h',
                        title="<b>Top 10 Empresas por Valor de Multa</b>",
                        labels={'label': 'Empresa', 'VAL_AUTO_INFRACAO_NUMERIC': 'Valor Total (R$)'},
                        text='VAL_AUTO_INFRACAO_NUMERIC',
                        color_discrete_sequence=['#ff6b6b']  # Cor diferente para empresas
                    )
                    
                    # Formata os valores no eixo X como moeda
                    fig_empresa.update_layout(
                        xaxis_tickformat=',.0f',
                        height=600,
                        margin=dict(l=250)  # Mais espa√ßo √† esquerda para os nomes
                    )
                    
                    # Formata os textos dos valores
                    fig_empresa.update_traces(
                        texttemplate='R$ %{x:,.0f}',
                        textposition='outside'
                    )
                    
                    st.plotly_chart(fig_empresa, use_container_width=True)
                    
                    # Mostra estat√≠sticas
                    total_empresa = empresa_grouped['VAL_AUTO_INFRACAO_NUMERIC'].sum()
                    st.caption(f"üí∞ Total: R$ {total_empresa:,.2f} | üè¢ {len(empresa_grouped)} empresas (dados √∫nicos)")
                else:
                    st.info("Nenhuma empresa encontrada nos dados filtrados.")
            else:
                st.info("Nenhuma empresa encontrada nos dados filtrados.")
            
            # Estat√≠sticas gerais no final
            total_identificados = len(df_pessoas_fisicas) + len(df_empresas)
            total_nao_identificados = len(df_clean) - total_identificados
            
            if total_nao_identificados > 0:
                st.info(f"üìä **Resumo Geral:** {len(df_pessoas_fisicas)} pessoas f√≠sicas, {len(df_empresas)} empresas, {total_nao_identificados} registros com formato de CPF/CNPJ n√£o identificado (todos dados √∫nicos)")
            else:
                st.info(f"üìä **Resumo Geral:** {len(df_pessoas_fisicas)} pessoas f√≠sicas, {len(df_empresas)} empresas identificadas (todos dados √∫nicos)")
                
        except Exception as e:
            st.error(f"Erro no gr√°fico de infratores: {e}")

    def create_infraction_map_advanced(self, selected_ufs: list, date_filters: dict):
        """Cria mapa de calor das infra√ß√µes com dados √∫nicos garantidos."""
        st.subheader("Mapa de Calor de Infra√ß√µes")
        
        try:
            df = self._get_filtered_data_advanced(selected_ufs, date_filters)
            
            if df.empty:
                st.warning("Nenhum dado encontrado.")
                return
            
            # Filtra dados com coordenadas
            required_cols = ['NUM_LATITUDE_AUTO', 'NUM_LONGITUDE_AUTO']
            if not all(col in df.columns for col in required_cols):
                st.warning("Dados de geolocaliza√ß√£o n√£o dispon√≠veis.")
                return
            
            with st.spinner("Carregando dados do mapa..."):
                # Remove valores vazios e converte coordenadas
                df_map = df[
                    df['NUM_LATITUDE_AUTO'].notna() & 
                    df['NUM_LONGITUDE_AUTO'].notna() &
                    (df['NUM_LATITUDE_AUTO'] != '') &
                    (df['NUM_LONGITUDE_AUTO'] != '')
                ].copy()
                
                if df_map.empty:
                    st.warning("Nenhuma coordenada v√°lida encontrada.")
                    return
                
                # Limita para performance (dados j√° s√£o √∫nicos)
                if len(df_map) > 5000:
                    df_map = df_map.sample(n=5000, random_state=42)  # random_state para reprodutibilidade
                
                # Converte coordenadas
                df_map['lat'] = pd.to_numeric(df_map['NUM_LATITUDE_AUTO'].astype(str).str.replace(',', '.'), errors='coerce')
                df_map['lon'] = pd.to_numeric(df_map['NUM_LONGITUDE_AUTO'].astype(str).str.replace(',', '.'), errors='coerce')
                
                # Remove coordenadas inv√°lidas
                df_map = df_map.dropna(subset=['lat', 'lon'])
                
                if not df_map.empty:
                    st.map(df_map[['lat', 'lon']], zoom=3)
                    st.caption(f"üìç Exibindo {len(df_map):,} pontos de {len(df):,} infra√ß√µes √∫nicas | {date_filters['description']}")
                else:
                    st.warning("Nenhuma coordenada v√°lida ap√≥s convers√£o.")
                    
        except Exception as e:
            st.error(f"Erro no mapa: {e}")

    def create_infraction_status_chart_advanced(self, selected_ufs: list, date_filters: dict):
        """Cria gr√°fico do status das infra√ß√µes com dados √∫nicos garantidos."""
        try:
            df = self._get_filtered_data_advanced(selected_ufs, date_filters)
            
            if df.empty or 'DES_STATUS_FORMULARIO' not in df.columns:
                return
            
            # Remove valores vazios
            df_clean = df[df['DES_STATUS_FORMULARIO'].notna() & (df['DES_STATUS_FORMULARIO'] != '')]
            
            if df_clean.empty:
                return
            
            # Conta infra√ß√µes por status (dados j√° s√£o √∫nicos)
            status_counts = df_clean['DES_STATUS_FORMULARIO'].value_counts().head(10)
            method_note = "infra√ß√µes √∫nicas (garantido)"
            
            if not status_counts.empty:
                chart_df = pd.DataFrame({
                    'DES_STATUS_FORMULARIO': status_counts.index,
                    'total': status_counts.values
                })
                
                chart_df['DES_STATUS_FORMULARIO'] = chart_df['DES_STATUS_FORMULARIO'].str.title()
                
                fig = px.bar(
                    chart_df.sort_values('total'), 
                    y='DES_STATUS_FORMULARIO', 
                    x='total', 
                    orientation='h',
                    title=f"<b>Est√°gio Atual das Infra√ß√µes (Top 10 - {method_note})</b>", 
                    text='total'
                )
                st.plotly_chart(fig, use_container_width=True)
                
        except Exception as e:
            st.error(f"Erro no gr√°fico de status: {e}")

    # ======================== M√âTODOS LEGACY (para compatibilidade) ========================

    def create_overview_metrics(self, selected_ufs: list, year_range: tuple):
        """M√©todo legacy - converte year_range para date_filters."""
        date_filters = {
            "mode": "simple",
            "years": list(range(year_range[0], year_range[1] + 1)),
            "year_range": year_range,
            "description": f"{year_range[0]}-{year_range[1]}"
        }
        return self.create_overview_metrics_advanced(selected_ufs, date_filters)

    def create_infraction_map(self, selected_ufs: list, year_range: tuple):
        """M√©todo legacy - converte year_range para date_filters."""
        date_filters = {
            "mode": "simple",
            "years": list(range(year_range[0], year_range[1] + 1)),
            "year_range": year_range,
            "description": f"{year_range[0]}-{year_range[1]}"
        }
        return self.create_infraction_map_advanced(selected_ufs, date_filters)

    def create_municipality_hotspots_chart(self, selected_ufs: list, year_range: tuple):
        """M√©todo legacy - converte year_range para date_filters."""
        date_filters = {
            "mode": "simple",
            "years": list(range(year_range[0], year_range[1] + 1)),
            "year_range": year_range,
            "description": f"{year_range[0]}-{year_range[1]}"
        }
        return self.create_municipality_hotspots_chart_advanced(selected_ufs, date_filters)

    def create_fine_value_by_type_chart(self, selected_ufs: list, year_range: tuple):
        """M√©todo legacy - converte year_range para date_filters."""
        date_filters = {
            "mode": "simple",
            "years": list(range(year_range[0], year_range[1] + 1)),
            "year_range": year_range,
            "description": f"{year_range[0]}-{year_range[1]}"
        }
        return self.create_fine_value_by_type_chart_advanced(selected_ufs, date_filters)

    def create_gravity_distribution_chart(self, selected_ufs: list, year_range: tuple):
        """M√©todo legacy - converte year_range para date_filters e inclui infra√ß√µes sem avalia√ß√£o."""
        date_filters = {
            "mode": "simple",
            "years": list(range(year_range[0], year_range[1] + 1)),
            "year_range": year_range,
            "description": f"{year_range[0]}-{year_range[1]}"
        }
        return self.create_gravity_distribution_chart_advanced(selected_ufs, date_filters)

    def create_state_distribution_chart(self, selected_ufs: list, year_range: tuple):
        """M√©todo legacy - converte year_range para date_filters."""
        date_filters = {
            "mode": "simple",
            "years": list(range(year_range[0], year_range[1] + 1)),
            "year_range": year_range,
            "description": f"{year_range[0]}-{year_range[1]}"
        }
        return self.create_state_distribution_chart_advanced(selected_ufs, date_filters)

    def create_infraction_status_chart(self, selected_ufs: list, year_range: tuple):
        """M√©todo legacy - converte year_range para date_filters."""
        date_filters = {
            "mode": "simple",
            "years": list(range(year_range[0], year_range[1] + 1)),
            "year_range": year_range,
            "description": f"{year_range[0]}-{year_range[1]}"
        }
        return self.create_infraction_status_chart_advanced(selected_ufs, date_filters)

    def create_main_offenders_chart(self, selected_ufs: list, year_range: tuple):
        """M√©todo legacy - converte year_range para date_filters."""
        date_filters = {
            "mode": "simple",
            "years": list(range(year_range[0], year_range[1] + 1)),
            "year_range": year_range,
            "description": f"{year_range[0]}-{year_range[1]}"
        }
        return self.create_main_offenders_chart_advanced(selected_ufs, date_filters)

    def force_refresh(self):
        """For√ßa atualiza√ß√£o dos dados limpando cache."""
        if self.paginator:
            self.paginator.clear_cache()
            st.success("üîÑ Cache limpo! Os dados ser√£o recarregados.")

    # ======================== M√âTODOS DE DIAGN√ìSTICO ========================

    def get_data_quality_info(self, selected_ufs: list = None, date_filters: dict = None) -> dict:
        """Retorna informa√ß√µes sobre a qualidade dos dados carregados."""
        try:
            if date_filters is None:
                date_filters = {
                    "mode": "simple",
                    "years": [2024, 2025],
                    "description": "Todos os dados"
                }
            
            # Obt√©m dados
            df = self._get_filtered_data_advanced(selected_ufs or [], date_filters)
            
            if df.empty:
                return {"error": "Nenhum dado dispon√≠vel"}
            
            # An√°lise de qualidade
            quality_info = {
                "total_records": len(df),
                "has_num_auto_infracao": 'NUM_AUTO_INFRACAO' in df.columns,
                "unique_infractions": df['NUM_AUTO_INFRACAO'].nunique() if 'NUM_AUTO_INFRACAO' in df.columns else 0,
                "null_num_auto": df['NUM_AUTO_INFRACAO'].isna().sum() if 'NUM_AUTO_INFRACAO' in df.columns else 0,
                "columns_count": len(df.columns),
                "memory_usage_mb": df.memory_usage(deep=True).sum() / 1024 / 1024,
                "date_range": {
                    "min": df['DAT_HORA_AUTO_INFRACAO'].min() if 'DAT_HORA_AUTO_INFRACAO' in df.columns else None,
                    "max": df['DAT_HORA_AUTO_INFRACAO'].max() if 'DAT_HORA_AUTO_INFRACAO' in df.columns else None
                },
                "states_count": df['UF'].nunique() if 'UF' in df.columns else 0,
                "municipalities_count": df['MUNICIPIO'].nunique() if 'MUNICIPIO' in df.columns else 0
            }
            
            # Verifica consist√™ncia
            if quality_info["has_num_auto_infracao"]:
                quality_info["data_consistency"] = quality_info["total_records"] == quality_info["unique_infractions"]
                quality_info["duplicate_records"] = quality_info["total_records"] - quality_info["unique_infractions"]
            else:
                quality_info["data_consistency"] = None
                quality_info["duplicate_records"] = None
            
            return quality_info
            
        except Exception as e:
            return {"error": f"Erro na an√°lise de qualidade: {str(e)}"}

    def display_data_quality_info(self, selected_ufs: list = None, date_filters: dict = None):
        """Exibe informa√ß√µes sobre a qualidade dos dados."""
        with st.expander("üîç Informa√ß√µes de Qualidade dos Dados"):
            quality_info = self.get_data_quality_info(selected_ufs, date_filters)
            
            if "error" in quality_info:
                st.error(quality_info["error"])
                return
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Total de Registros", f"{quality_info['total_records']:,}")
                if quality_info['has_num_auto_infracao']:
                    st.metric("Infra√ß√µes √önicas", f"{quality_info['unique_infractions']:,}")
                else:
                    st.warning("Coluna NUM_AUTO_INFRACAO n√£o encontrada")
            
            with col2:
                st.metric("Estados", quality_info['states_count'])
                st.metric("Munic√≠pios", quality_info['municipalities_count'])
            
            with col3:
                st.metric("Colunas", quality_info['columns_count'])
                st.metric("Uso de Mem√≥ria", f"{quality_info['memory_usage_mb']:.1f} MB")
            
            # Consist√™ncia dos dados
            if quality_info['data_consistency'] is not None:
                if quality_info['data_consistency']:
                    st.success("‚úÖ Dados consistentes - sem duplicatas")
                else:
                    st.warning(f"‚ö†Ô∏è {quality_info['duplicate_records']} registros duplicados removidos")
            
            # Range de datas
            if quality_info['date_range']['min'] and quality_info['date_range']['max']:
                st.info(f"üìÖ Per√≠odo: {quality_info['date_range']['min']} a {quality_info['date_range']['max']}")
